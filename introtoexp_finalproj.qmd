---
title: "Intro to experiment methods final project"
format: html
editor: visual
---

PCIbex link: https://farm.pcibex.net/r/jmAAMx/

```{r}
library(ggplot2)
library(stringr)
library(lmerTest)
library(lme4)
library(broom.mixed)
library(car)
library(flextable)
library(tidyverse)
```

```{r}
results = read.csv("~/Desktop/introtoexp/Labsandhomework/results.csv")

results_clean = results %>% 
  mutate(RT = as.numeric(RT)) %>%
  filter(RT <= 1000) %>%
  mutate(logRT = log(RT),
    finiteness = ifelse(ConditionID %in% c("A","B"), "infinitival", "finite"),
    plausibility= ifelse(ConditionID %in% c("A","C"), "plausible",   "implausible"))

head(results_clean)
```

```{r}
target_verbs <- c("expand","prepare","battle","warn","call","ask","benefit","aim",
                  "continue","improve","caution","coordinate","compensate","argue",
                  "provide","allow","help")

past_verbs <- ifelse(str_ends(target_verbs, "e"),
                     paste0(target_verbs, "d"),
                     paste0(target_verbs, "ed"))

all_verbs <- tolower(c(target_verbs, past_verbs))

adv_phrases <- c(
  "tastefully and creatively", "far in advance", "fiercely and relentlessly",
  "with great force", "without any delay", "in an email", "to the fullest extent",
  "with perfect accuracy", "without any interruption", "in many ways",
  "strongly and emphatically", "sternly and seriously", "in every detail",
  "quickly and completely", "hurriedly and efficiently", "for many months",
  "promptly and fully", "drastically and innovatively", "using controversial evidence",
  "at minimal cost", "during the morning", "in useful ways",
  "dramatically and creatively", "regularly and systematically"
)

adv_phrase_lists <- str_split(adv_phrases, " ")

results_clean <- results_clean %>%
  mutate(word_lower = tolower(Word)) %>%
  arrange(ParticipantID, Sentence, WordPosition)

crit_verb <- results_clean %>%
  group_by(ParticipantID, Sentence) %>%
  mutate(prev_word = lag(word_lower)) %>%
  ungroup() %>%
  filter(word_lower %in% all_verbs & prev_word %in% c("to", "that"))

get_critical_region <- function(df, crit_verbs, adv_list) {
  output <- list()

  for (i in 1:nrow(crit_verbs)) {
    row <- crit_verbs[i, ]
    pid <- row$ParticipantID
    sent <- row$Sentence
    pos <- row$WordPosition
    fin <- row$finiteness
    plau <- row$plausibility

    this_sent <- df %>%
      filter(ParticipantID == pid, Sentence == sent) %>%
      arrange(WordPosition)

    region_words <- this_sent %>% filter(WordPosition == pos)

    for (adv in adv_list) {
      adv_len <- length(adv)
      candidate <- this_sent %>% filter(WordPosition %in% (pos + 1):(pos + adv_len))

      if (nrow(candidate) == adv_len &&
          all(tolower(candidate$Word) == adv)) {
        region_words <- bind_rows(region_words, candidate)
        break
      }
    }

    region_words <- region_words %>%
      mutate(region_id = paste(ParticipantID, Sentence, WordPosition, sep = "_"),
        ParticipantID = pid,
        Sentence = sent,
        finiteness = fin,
        plausibility = plau
      )

    output[[length(output) + 1]] <- region_words
  }

  bind_rows(output)
}

crit_region_df <- get_critical_region(results_clean, crit_verb, adv_phrase_lists)

region_summary <- crit_region_df %>%
  group_by(region_id, ParticipantID, Sentence, finiteness, plausibility) %>%
  summarize(mean_logRT = mean(logRT, na.rm = TRUE), .groups = "drop")


```

```{r}
crit_verb %>%
  count()
crit_region_df %>%
  select(ParticipantID, Sentence, Word, WordPosition, logRT)

```


```{r}
ggplot(crit_verb, aes(x = finiteness, y = logRT, fill = plausibility)) +
  geom_boxplot()+
  labs(x = "Finiteness", y = "RT") +
  theme_minimal()
```

```{r}
crit_verb.lm=lm(logRT ~ finiteness * plausibility, data = crit_verb); summary(crit_verb.lm)
crit_verb.m1=lmer(logRT ~ finiteness * plausibility +(1 | ParticipantID), data = crit_verb, REML = F); summary(crit_verb.m1)
crit_verb.m2=lmer(logRT ~ finiteness * plausibility +(1 | ParticipantID) + (1 | Word), data = crit_verb, REML = F); summary(crit_verb.m2)
crit_verb.m3=lmer(logRT ~ finiteness * plausibility +(1+finiteness*plausibility | ParticipantID) + (1 | Word), data = crit_verb, REML = F); summary(crit_verb.m3)
crit_verb.m4=lmer(logRT ~ finiteness * plausibility +(1+finiteness*plausibility | ParticipantID) + (1+plausibility | Word), data = crit_verb, REML = F); summary(crit_verb.m4)
```

```{r}
anova(crit_verb.m4, crit_verb.m3)
anova(crit_verb.m3, crit_verb.m2)
anova(crit_verb.m2, crit_verb.m1)
anova(crit_verb.m1, crit_verb.lm)
```

```{r}
m1_results = broom.mixed::tidy(crit_verb.m1, effects = "fixed") %>%
  mutate(Estimate = round(estimate, 3), SE = round(std.error, 3), t = round(statistic, 2), p = ifelse(p.value < 0.001, "< .001", paste0(round(p.value, 3)))) %>%
  select(term, Estimate, SE, t, p)
m1_table = flextable(m1_results %>% dplyr::rename("Predictor" = term)) %>%
  autofit() %>%
  width(j = "Predictor", width = 2) %>%
  width(j = c("Estimate", "SE", "t", "p"), width = 1) %>%
  fontsize(size = 9) %>%
  set_table_properties(width = 0.8) %>%
  theme_apa() %>%
  color(color = "black", part = "all")

m1_table
```

```{r}
tidy(crit_verb.m1) %>% 
  filter(effect == "fixed")
```

```{r}
plot(crit_verb.m1)
plot(fitted(crit_verb.m1), residuals(crit_verb.m1))
```

```{r}
vif(crit_verb.m1)
```

```{r}
qqnorm(residuals(crit_verb.m1)); qqline(residuals(crit_verb.m1))
shapiro.test(residuals(crit_verb.m1))
```

```{r}
plot(fitted(crit_verb.m1), residuals(crit_verb.m1, type = "pearson"))
leveneTest(residuals(crit_verb.m1) ~ interaction(crit_verb$finiteness, crit_verb$plausibility))
```

```{r}
influencePlot(crit_verb.m1)
```

```{r}
CooksDistance_accuracy = rownames(influencePlot(crit_verb.m1)) %>% 
  as.numeric()
  
crit_verb[c(CooksDistance_accuracy),]
```

```{r}
lmer(logRT ~ finiteness * plausibility +(1 | ParticipantID), data = crit_verb, REML = F,  subset = -CooksDistance_accuracy)%>%summary()
```
